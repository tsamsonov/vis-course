{
  "hash": "29eb135f666b8fb1a15e5857aa81e100",
  "result": {
    "engine": "jupyter",
    "markdown": "---\ntitle: Классификация одномерных рядов\nsubtitle: Визуализация пространственных данных\ndate: today\ndate-format: long\nauthor: Самсонов Тимофей Евгеньевич\nexecute:\n  echo: false\n  freeze: true\nformat:\n  revealjs:\n    theme:\n      - default\n      - custom.scss\n    margin: 0.2\n    width: 1280\n    height: 720\n    slide-number: true\n    footer: 'Самсонов Т. Е. Визуализация пространственных данных: курс лекций'\n    header-includes: '<link rel=\"stylesheet\" media=\"screen\" href=\"https://fontlibrary.org//face/pt-sans\" type=\"text/css\"/>'\nbibliography: references.yaml\nmainfont: PT Sans\n---\n\n## Функция распределения\n\nФункция распределения $F(x) = P(X < x)$ является одной из основных характеристик случайной величины.\n\nВ практической работе используется выборочная ФР $\\widehat F(x)$.\n\n::: {#f8d5c2fe .cell execution_count=1}\n\n::: {.cell-output .cell-output-display}\n![](02_Classifications_files/figure-revealjs/cell-2-output-1.png){width=995 height=540}\n:::\n:::\n\n\n## Выборочная функция распределения\n\n**Выборочная функция распределения** $\\widehat F(x)$ определяется следующим образом:\n\n$$\n\\widehat F(x) = \\frac{1}{n}\\sum_{i=1}^n \\theta(x-X_i),\n$$\n\nгде $\\theta(x)$ — *функция Хевисайда*:\n\n$$\n\\theta(x)=\\begin{cases} 0, & x<0;\n\\\\ 1, & x\\geqslant 0.\\end{cases}\n$$\n\nПри $n \\rightarrow \\infty$ функция $\\widehat F(x)$ равномерно сходится к $F(x)$ (*теорема Колмогорова*).\n\n::: callout-tip\n## Проще говоря\n\nЧем больше выборка, тем точнее выборочная ФР описывает реальную.\n:::\n\n## Нормальное распределение\n\n$$\n\\Phi(x) = \\frac 1 {\\sqrt{2\\pi}} \\int\\limits_{-\\infty}^{x} e^{-t^2/2} \\, dt.\n$$\n\n::: {#4ce46eb3 .cell execution_count=2}\n\n::: {.cell-output .cell-output-display}\n![](02_Classifications_files/figure-revealjs/cell-3-output-1.png){width=995 height=540}\n:::\n:::\n\n\n## Логнормальное распределение\n\n$$\nF(x) = \\Phi\\left( \\frac{(\\ln x) - \\mu} \\sigma \\right) \n$$\n\n::: {#913b4068 .cell execution_count=3}\n\n::: {.cell-output .cell-output-display}\n![](02_Classifications_files/figure-revealjs/cell-4-output-1.png){width=995 height=540}\n:::\n:::\n\n\n## Экспоненциальное распределение\n\n$$\nF(x) = \\left\\{\\begin{matrix}\n1-e^{-\\lambda x}&,\\; x \\ge 0, \\\\\n0 &,\\; x < 0.\n\\end{matrix}\\right.\n$$\n\n::: {#867f4f98 .cell execution_count=4}\n\n::: {.cell-output .cell-output-display}\n![](02_Classifications_files/figure-revealjs/cell-5-output-1.png){width=995 height=540}\n:::\n:::\n\n\n## Равные интервалы\n\nРазмер класса равен $[\\max(X) - \\min(X)] / k$, где $k$ — число классов.\n\n::: {#7bfec4e8 .cell execution_count=5}\n\n::: {.cell-output .cell-output-display}\n![](02_Classifications_files/figure-revealjs/cell-6-output-1.png){width=1014 height=559}\n:::\n:::\n\n\n## Квантили\n\nКоличество элементов в каждом классе $c \\approx n/k$.\n\n::: {#8ee26b52 .cell execution_count=6}\n\n::: {.cell-output .cell-output-display}\n![](02_Classifications_files/figure-revealjs/cell-7-output-1.png){width=1014 height=559}\n:::\n:::\n\n\n## Стандартные отклонения\n\nГраницы классов определяются значениями $\\overline X \\pm \\alpha S$, где $\\alpha = 1, 2, ..., (k+1)/2$\n\n::: {#103945a4 .cell execution_count=7}\n\n::: {.cell-output .cell-output-display}\n![](02_Classifications_files/figure-revealjs/cell-8-output-1.png){width=1014 height=559}\n:::\n:::\n\n\n> Метод подходит только для данных с нормальным распределением.\n\n## Стандартные отклонения\n\nДанный метод не подходит для распределений, отличающихся от нормального. Например, для экспоненциального:\n\n::: {#6741dd3e .cell execution_count=8}\n\n::: {.cell-output .cell-output-display}\n![](02_Classifications_files/figure-revealjs/cell-9-output-1.png){width=1031 height=559}\n:::\n:::\n\n\n> Метод подходит только для данных с нормальным распределением.\n\n## Метод Дженкса-Кэспалла (1971)\n\nГраницы классов определяются путем минимизации суммы расстояний от элементов классов до их медиан (*ADCM* — a*bsolute deviation about class median*):\n\n$$\nADCM = \\sum_{j=1}^k \\sum_{i=1}^{n_k} |X_{ij} - \\operatorname{med}(X_j)|\n$$\n\nМетод базируется на итеративном алгоритме:\n\n1.  Классифицировать выборку методом квантилей на $k$ классов.\n2.  Вычислить для каждого элемента его отклонение от медианы собственного *и соседних* классов.\n3.  Пока есть элементы, располагающиеся ближе к соседней медиане, чем к своей:\n    -   Переместить элемент в ближайший соседний класс\n    -   Обновить значения медиан и расстояний для изменившихся классов и их соседей\n\n## Метод Дженкса-Кэспалла (1971)\n\nГраницы классов определяются путем минимизации ADCM\n\n::: {#fbb05dae .cell execution_count=9}\n\n::: {.cell-output .cell-output-display}\n![](02_Classifications_files/figure-revealjs/cell-10-output-1.png){width=1014 height=559}\n:::\n:::\n\n\n## Метод Фишера-Дженкса (1958, 1977)\n\nТак же как и метод Дженкса-Кэспалла, минимизирует ADCM, однако использует *рекурсивную*, а не итеративную процедуру. В основе лежит теорема:\n\n> Каждое оптимальное разбиение множества есть объединение оптимальных разбиение его подмножеств\n\nТогда границей $j$ оптимального разбиения $X$ на 2 класса будем считать\n\n$$\n\\operatorname{argmin}_j \\big[D(1, j) + D(j+1, n)\\big],\\\\D(a, b) = \\sum_{i = a}^b |X_i - \\operatorname{med}(X_{[a,b]})|\n$$\n\nЕсли число классов $k > 2$, то выбирается тот из них, у которого максимальное значение $D$ и аналогичным образом разбивается на $2$ класса.\n\n## Метод Фишера-Дженкса (1958, 1977)\n\nДанный метод также известен автоматизированный вариант классификации методом *Natural Breaks*\n\n::: {#51a52a06 .cell execution_count=10}\n\n::: {.cell-output .cell-output-display}\n![](02_Classifications_files/figure-revealjs/cell-11-output-1.png){width=1014 height=559}\n:::\n:::\n\n\n## Метод Head/Tail (Jiang, 2013)\n\nВ данном методе используется рекурсивное разбиение выборки средним значением.\n\n1.  Разбить выборку на $2$ класса, используя среднее значение\n2.  Повторять процедуру для класса выше среднего, до тех пор пока не будет достигнуто\n    -   требуемое число классов или\n    -   доля значений выше среднего не превысит $40\\%$\n\nПороговый критерий в $40\\%$ является экспертным (предложен автором метода) и может быть модифицирован.\n\n> Метод годится для распределений с \"тяжелым хвостом\", т.е. подчиняющихся экспоненциальному закону.\n\n## Метод Head/Tail (Jiang, 2013)\n\nДанный метод плохо работает с нормальным распределением:\n\n::: {#89dc10d8 .cell execution_count=11}\n\n::: {.cell-output .cell-output-display}\n![](02_Classifications_files/figure-revealjs/cell-12-output-1.png){width=1014 height=559}\n:::\n:::\n\n\n## Метод Head/Tail (Jiang, 2013)\n\nНо хорошо справляется с экспоненциальным:\n\n::: {#bff9d507 .cell execution_count=12}\n\n::: {.cell-output .cell-output-display}\n![](02_Classifications_files/figure-revealjs/cell-13-output-1.png){width=1031 height=559}\n:::\n:::\n\n\n## GADF \n\n**GADF** **(Goodness of Absolute Deviation Fit)** — метрика, характеризующая эффективность классификации:\n\n$$\nGADF = 1 - \\frac{\\sum_{j=1}^k \\sum_{i=1}^{n_k} |X_{ij} - \\operatorname{med}(X_j)|}{\\sum_{i=1}^{n} |X_{i} - \\operatorname{med}(X)|}\n$$\n\nGADF показывает как отклонения внутри классов соотносятся с отклонениями всей выборки. Чем\n\n::: callout-tip\n## Применение\n\nМетрику GADF можно использовать для того чтобы определить оптимальный метод классификации\n:::\n\n## GADF \n\n**GADF** для **нормального** распределения:\n\n::: {#1a3b4279 .cell execution_count=13}\n\n::: {.cell-output .cell-output-display}\n![](02_Classifications_files/figure-revealjs/cell-14-output-1.png){width=995 height=603}\n:::\n:::\n\n\n## GADF \n\n**GADF** для **экспоненциального** распределения:\n\n::: {#3ac349e5 .cell execution_count=14}\n\n::: {.cell-output .cell-output-display}\n![](02_Classifications_files/figure-revealjs/cell-15-output-1.png){width=995 height=603}\n:::\n:::\n\n\n## Полезные функции\n\n+-------------------------------------+--------------------------------------------------------+\n| Функция                             | Назначение                                             |\n+=====================================+========================================================+\n| `x = np.random.exponential()`       | генерация экспоненциальной выборки                     |\n+-------------------------------------+--------------------------------------------------------+\n| `x = np.random.normal()`            | генерация нормальной выборки                           |\n+-------------------------------------+--------------------------------------------------------+\n| `x = np.random.lognormal()`         | генерация логнормальной выборки                        |\n+-------------------------------------+--------------------------------------------------------+\n| `matplotlib.pyplot.ecdf(x)`         | визуализация выборочной ФР                             |\n+-------------------------------------+--------------------------------------------------------+\n| `classes = mapclassify.<method>(x)` | классификация методами `mapclassify`                   |\n+-------------------------------------+--------------------------------------------------------+\n| `breaks = classes.bins`             | извлечение границ классов                              |\n+-------------------------------------+--------------------------------------------------------+\n| `gadf = classes.get_gadf()`         | извлечение GADF                                        |\n+-------------------------------------+--------------------------------------------------------+\n| `plt.vlines(breaks)`                | визуализация линий классов на графике $F(x)$           |\n+-------------------------------------+--------------------------------------------------------+\n| `for brk in breaks:`                | визуализация значений границ классов на графике $F(x)$ |\n|                                     |                                                        |\n| `plt.text(brk,...)`                 |                                                        |\n+-------------------------------------+--------------------------------------------------------+\n\n## Библиография\n\n",
    "supporting": [
      "02_Classifications_files"
    ],
    "filters": [],
    "includes": {}
  }
}